# 游댧 CLASIFICACI칍N AVANZADA DE C츼NCER DE MAMA (Breast Cancer Wisconsin) 游낀

Este proyecto implementa y compara m칰ltiples modelos de Machine Learning para clasificar tumores mamarios como **Benignos** (Clase 1) o **Malignos** (Clase 0), utilizando el popular conjunto de datos Breast Cancer Wisconsin (Diagn칩stico) de scikit-learn.

El objetivo principal es identificar el modelo con la **mayor capacidad predictiva** (medida principalmente por el 치rea bajo la curva ROC, **AUC-ROC**) para asistir en el diagn칩stico temprano con alta fiabilidad.

## 丘뙖잺 Configuraci칩n y Librer칤as

El an치lisis fue ejecutado utilizando las siguientes bibliotecas clave de Python:

* **Scikit-learn (sklearn):** Para la carga del dataset, preprocesamiento, implementaci칩n de modelos y m칠tricas.
* **NumPy:** Para operaciones num칠ricas eficientes.
* **Pandas:** Para manipulaci칩n y exploraci칩n de datos.
* **Matplotlib y Seaborn:** Para la generaci칩n de gr치ficos de visualizaci칩n de resultados.

## 游늵 Dataset y Preprocesamiento

### Resumen del Dataset

| Caracter칤stica | Valor |
| :--- | :--- |
| **Total de Muestras** | 569 |
| **Caracter칤sticas (Features)** | 30 (ej. *mean radius*, *mean texture*) |
| **Clases** | Maligno (0) y Benigno (1) |
| **Distribuci칩n de Clases** | Maligno: 212 muestras (**37.3%**) |
| | Benigno: 357 muestras (**62.7%**) |



El conjunto de datos est치 ligeramente desbalanceado, pero la estratificaci칩n en el `train_test_split` asegura una representaci칩n equitativa de las clases.

### Pasos de Preprocesamiento

1.  **Divisi칩n de Datos:** El dataset se dividi칩 en conjuntos de **Entrenamiento (80%)** y **Prueba (20%)** utilizando la funci칩n `train_test_split` con `stratify=y` para mantener la proporci칩n de clases.
2.  **Escalado de Caracter칤sticas:** Se aplic칩 el `StandardScaler` a todas las caracter칤sticas. Esto es crucial para modelos basados en distancia (como KNN y SVM) y para la Regresi칩n Log칤stica, ya que asegura que todas las caracter칤sticas contribuyan equitativamente, independientemente de su escala original.

## 游 Modelos Evaluados

Se entrenaron y compararon cinco modelos de clasificaci칩n avanzados:

| Modelo | Tipo | Notas Clave |
| :--- | :--- | :--- |
| **KNeighbors Classifier (KNN)** | Basado en Instancias | Utiliza la distancia a los 5 vecinos m치s cercanos (`n_neighbors=5`). |
| **Random Forest** | Ensamblaje (Bagging) | 200 치rboles de decisi칩n (`n_estimators=200`) para reducir el sobreajuste. |
| **Support Vector Machine (SVM)** | Basado en Kernel | Utiliza un kernel RBF para mapear datos a un espacio de mayor dimensi칩n. |
| **Logistic Regression** | Lineal | Modelo simple que predice la probabilidad de pertenencia a una clase. |
| **Gradient Boosting** | Ensamblaje (Boosting) | Construye secuencialmente 치rboles d칠biles, corrigiendo los errores del anterior. |

## 游꿢 Resultados de la Evaluaci칩n

El rendimiento se evalu칩 utilizando la **Precisi칩n (Accuracy)** en el conjunto de prueba, la **Validaci칩n Cruzada (5-Fold)** y la m칠trica clave: el **츼rea bajo la Curva ROC (AUC-ROC)**.

### Tabla de Rendimiento

| Modelo | Precisi칩n (Test) | CV (Media 췀 Desv. Est.) | AUC-ROC |
| :--- | :--- | :--- | :--- |
| **KNN** | 96.49% | 97.58% 췀 1.13% | 0.992 |
| **Random Forest** | 95.61% | 96.92% 췀 1.83% | 0.989 |
| **SVM** | 98.25% | **97.80% 췀 1.25%** | **0.999** |
| **Logistic Regression** | 98.25% | 97.58% 췀 1.39% | 0.998 |
| **Gradient Boosting** | 95.61% | 96.70% 췀 1.88% | 0.985 |

### 游끥 Mejor Modelo

El modelo seleccionado como el mejor es el **Support Vector Machine (SVM)**, ya que alcanz칩 el AUC-ROC m치s alto.

* **SVM:** AUC-ROC = **0.999** (La capacidad de discriminaci칩n es casi perfecta).
* **Precisi칩n en Test:** **98.25%**

## 游늳 An치lisis Gr치fico de Resultados

Los resultados completos se visualizan en el gr치fico `analisis_cancer_completo.png` generado por el script.

### 1. Curva ROC

La curva ROC (Receiver Operating Characteristic) mide la capacidad del modelo para distinguir entre clases. Un AUC cercano a 1.0 indica una excelente discriminaci칩n.



**Observaci칩n Clave:** Los modelos **SVM** y **Regresi칩n Log칤stica** muestran curvas casi perfectas, superando a los dem치s en la m칠trica m치s importante para diagn칩stico.

### 2. Matriz de Confusi칩n (Mejor Modelo: SVM)

La matriz de confusi칩n del modelo SVM confirma su rendimiento casi perfecto, minimizando los errores de clasificaci칩n, especialmente los **Falsos Negativos (FN)** (un diagn칩stico maligno perdido), lo cual es cr칤tico en medicina.

| Etiqueta Real / Predicha | Maligno (0) | Benigno (1) |
| :--- | :--- | :--- |
| **Maligno (0)** | 40 (Verdaderos Negativos) | 1 (Falso Positivo) |
| **Benigno (1)** | 0 (Falso Negativo) | 73 (Verdaderos Positivos) |

**Error Cr칤tico Cero:** El modelo SVM no cometi칩 **ning칰n Falso Negativo** en el conjunto de prueba (0 casos malignos fueron predichos err칩neamente como benignos), lo que lo hace excepcionalmente fiable desde una perspectiva cl칤nica.

### 3. Importancia de Caracter칤sticas (Random Forest)

Si el mejor modelo no proporciona importancia de caracter칤sticas (como el SVM cl치sico), se analiza el siguiente mejor modelo de ensamblaje (Random Forest).

**Top 5 Caracter칤sticas m치s Importantes (Random Forest):**

1.  **Worst perimeter**
2.  **Worst area**
3.  **Worst radius**
4.  **Mean concave points**
5.  **Mean perimeter**

## 游눠 An치lisis de Regresi칩n Log칤stica (Impacto de Caracter칤sticas)

El an치lisis de coeficientes del modelo de Regresi칩n Log칤stica, despu칠s del escalado, revela las caracter칤sticas que tienen el mayor impacto en la clasificaci칩n:

| Caracter칤stica | Coeficiente | Impacto |
| :--- | :--- | :--- |
| **Worst fractal dimension** | 1.15 | Mayor probabilidad de ser **Benigno** (Clase 1) |
| **Smoothness error** | 1.04 | Mayor probabilidad de ser **Benigno** (Clase 1) |
| **Worst smoothness** | -0.76 | Mayor probabilidad de ser **Maligno** (Clase 0) |
| **Worst concavity** | -0.66 | Mayor probabilidad de ser **Maligno** (Clase 0) |
| **Worst perimeter** | -0.58 | Mayor probabilidad de ser **Maligno** (Clase 0) |

Los coeficientes negativos (e.g., *Worst smoothness*, *Worst concavity*, *Worst perimeter*) se asocian con la clase Maligna (0), mientras que los positivos (e.g., *Worst fractal dimension*) se asocian con la clase Benigna (1).

## 游닉 Conclusi칩n Final

El an치lisis demuestra que los modelos **Support Vector Machine (SVM)** y **Logistic Regression** son los m치s adecuados para este problema de clasificaci칩n.

El modelo **SVM** se establece como el ganador con un **AUC-ROC de 0.999** y una **Precisi칩n del 98.25%**, crucialmente, sin cometer **Falsos Negativos** en el conjunto de prueba. Esto lo convierte en una herramienta altamente confiable para la asistencia al diagn칩stico cl칤nico de c치ncer de mama.

Para futuros pasos, se podr칤a considerar la optimizaci칩n de hiperpar치metros de estos modelos ganadores para intentar alcanzar la precisi칩n perfecta.
